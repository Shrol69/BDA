{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e2394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count, explode, split, lower\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BDA Lab: Titanic MapReduce\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the Titanic CSV into a DataFrame\n",
    "df = spark.read.csv(\"Titanic-Dataset.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# 1. Basic exploration\n",
    "df.show(5)\n",
    "print(f\"Total rows: {df.count()}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "\n",
    "# 2. Select relevant columns\n",
    "df_selected = df.select(\"PassengerId\", \"Survived\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"Fare\")\n",
    "df_selected.show(5)\n",
    "\n",
    "# 3. Count passengers per class\n",
    "passengers_per_class = df_selected.groupBy(\"Pclass\").count()\n",
    "passengers_per_class.show()\n",
    "\n",
    "# 4. Survival rate (%) per class\n",
    "survival_rate = df_selected.groupBy(\"Pclass\").agg((avg(\"Survived\") * 100).alias(\"survival_rate_percent\"))\n",
    "survival_rate.show()\n",
    "\n",
    "# 5. Average age per class\n",
    "avg_age_per_class = df_selected.groupBy(\"Pclass\").agg(avg(\"Age\").alias(\"avg_age\"))\n",
    "avg_age_per_class.show()\n",
    "\n",
    "# 6. Most common first names among survivors\n",
    "#    - Split the 'Name' column on comma or period to extract first names\n",
    "survivors = df_selected.filter(col(\"Survived\") == 1)\n",
    "names_df = survivors.withColumn(\n",
    "    \"first_name\",\n",
    "    lower(\n",
    "        split(col(\"Name\"), \"[,\\\\. ]+\")[1]  # picks the first name after the title\n",
    "    )\n",
    ")\n",
    "# Filter only alphabetic names\n",
    "names_df = names_df.filter(col(\"first_name\").rlike(\"^[a-z]+$\"))\n",
    "\n",
    "# Count and show the top 10 first names\n",
    "first_name_counts = names_df.groupBy(\"first_name\").count()\n",
    "top_first_names = first_name_counts.orderBy(col(\"count\").desc()).limit(10)\n",
    "top_first_names.show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
